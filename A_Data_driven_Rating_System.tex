\section{A Data-driven Rating System}\label{sec:club_rating}

As an alternative to direct human assessment ratings (whether self-assessment or captain-assessment), we advocate instead for a data-driven rating system that considers each player's history within BUDA club leagues. Unlike recreational leagues in which players are randomly assigned to teams according to skill level, players in club leagues form their own teams and select a division of competition which they believe to be appropriate to their team-wide skill level.  There are four divisions ranging from casual (Division 4) to highly competitive (Division 1).

Each club team uses a vetting process to determine whether or not a player can join their team. This is often as simple as a friend's recommendation, but it can also be as involved as a multi-day tryout. The key point is that in order to join a team, a player must have exhibited evidence that they will be competent at the skill level of the division in which that team competes.

Based on our experience of playing in different BUDA club league divisions, we begin by assigning the following ratings to each division in the style of the Elo system\footnote{https://en.wikipedia.org/wiki/Elo_rating_system}: Division 1: 1800, Division 2: 1400, Division 3: 1100, and Division 4: 900.  The idea is that a Division 1 team is expected to beat a Division 2 team 90\% of the time, a Division 2 team expects to win 85\% of the time against a Division 3 team, and a Division 3 team expects to beat a Division 4 team 75\% of the time.

The next step is to acknowledge that within each division, there is a wide range of team-wide skill level. Our experience with BUDA suggests that a weak Division 1 team is comparable to a strong division 2 team.  With this in mind, we calculate team ratings as the following:

\begin{equation}
{\rm Rating}_{\rm team} = {\rm Rating}_{\rm division} + 60 \times {\rm PPGD},
\end{equation}

\noindent where ${\rm PPGD}$ is the points per game differential for that team. Under this definition, a Division 1 team that loses on average by 3.3 points per game has an equal rating to a Division 2 team that wins on average by 3.3 points per game.

This methodology yields a team rating for every club team in the BUDA database. The club-assessment rating for a given player is the arithmetic mean of all of their team ratings leading up to that point in time. Here is a concrete example. Suppose a player has experience on an average Division 1 team $({\rm PPGD} = 0)$, a strong Division 2 team $({\rm PPGD} = 3)$, and an average Division 2 team $({\rm PPGD} = 0)$. In this scenario, their club-assessment rating will be $\frac{1}{3}(1800 + 1580 + 1400) = 1593$.

The last step that is unique to assigning a club-assessment rating to a player is the conversion to the same 0 to 100 scale used by BUDA for self-assessment ratings and captain-assessment ratings. The simple philosophy guiding this process is our experience with BUDA, which suggests that an average Division 1 player will have a club-assessment rating of 80, while an average Division 2 player will have a club-assessment rating of 60. An average Division 3 player gets a club-assessment rating of 45 and an average Division 4 player gets a club-assessment rating of 30. We use interpolation to fill in the gaps for ratings between these values.

Figure~\ref{fig:correlation_club} shows the relationship between club-assessment rating and team performance (as measured by points per game differential). Club-assessment rating correlates more strongly with team performance than captain-assessment rating ($r = 0.43$ for club-assessment rating, $r = 0.31$ for captain rating). This demonstrates that club-assessment rating is a better predictor of team performance than captain-assessment rating---and a much better predictor than self-assessment rating. If a player has a high club-assessment rating, that is a very strong indicator that they are a good player (and vice versa).

One of the limitations of the club-assessment rating method is that there are players without any club league experience.  On average, a roster of 16 players can expect to have 3 players without club experience. Although this is better than the average of 4 players that typically do not have a captain rating---see Section~\ref{sec:self_rating}---it must still be taken into consideration. Some of these are players new to ultimate or new to the Boston area. Individual self-assessment ratings are the only means by which to rate these players. Other players have significant experience in recreational leagues, but zero experience in club leagues. For this latter subset of players, we use a captain rating if available. 

We wish to emphasize that the club-assessment rating method outlined in this section requires no manual input by humans to function, unlike captain ratings and individual self-assessment ratings. The primary effort lies in recording who plays on what team and how those teams do. BUDA has shown that collecting and storing the data is not only feasible, but often an automatic part of running the league. This paper shows how to use the data to make real improvements in rating systems.

Finally, it is instructive to consider the practical implications of the findings in this section. In particular, how would the roster of the worst team need to be changed to yield an average team? The difference in club-assessment rating between the worst team (about 43) and an average team (about 51) is 8 rating points per player. On a team with 16 players, this corresponds to 128 total rating points. The best players have club-assessment ratings in the range 80 - 90, while average players have ratings in the range 45 - 55, and the worst players have club-assessment ratings between 10 - 20. To achieve a swing of 128 total rating points requires significant roster changes---even replacing a very weak player (rating of 15) with a very strong player (rating of 85) is insufficient because it brings about a change of only 70 points. Repeating this process (i.e., taking the two worst players on the team and replacing them with superstars) is barely sufficient to turn a terrible team into an above average team. Indeed, balancing the teams created by the existing BUDA rating system requires significant roster adjustments. 